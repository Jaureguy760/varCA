from snakemake.utils import min_version

##### set minimum snakemake version #####
min_version("5.5.0")

configfile: "configs/classify.yaml"


rule all:
    input:
        expand(
            config['out']+"/{sample}/results.tsv.gz",
            sample=config['predict']
        ) + expand(
            config['out']+"/{sample}/prc/results.png",
            sample=[
                s for s in config['predict']
                if 'truth' in config['data'][s] and config['data'][s]['truth']
            ] if 'prcols' in config and isinstance(config['prcols'], dict) else []
        ) + expand(
            config['out']+"/{sample}/tune.png",
            sample=config['train'] if 'tune' in config and config['tune'] else []
        )

rule apply_filters:
    """ apply filtering on the data according to the filtering expressions """
    input: lambda wildcards: config['data'][wildcards.sample]['path']
    params: lambda wildcards: "\t".join(config['data'][wildcards.sample]['filter'])
    output: config['out']+"/{sample}/filter.tsv.gz"
    conda: "envs/classify.yml"
    shell:
        "zcat {input} | scripts/filter.bash {params} | gzip > {output}"

rule annotate:
    """ create a table of annotations at each site """
    input: lambda wildcards: rules.apply_filters.output \
        if 'filter' in config['data'][wildcards.sample] and \
        config['data'][wildcards.sample]['filter'] else config['data'][wildcards.sample]['path']
    output: temp(config['out']+"/{sample}/annot.tsv.gz")
    conda: "../envs/classify.yml"
    shell:
        "zcat {input} | scripts/cgrep.bash - -E '^CHROM$|^POS$|~CLASS:' | gzip > {output}"


def prepared_data(wildcards):
    """ return the path to the prepared data """
    if 'filter' in config['data'][wildcards.sample] and config['data'][wildcards.sample]['filter']:
        return rules.apply_filters.output
    else:
        return config['data'][wildcards.sample]['path']

rule add_truth:
    """
        Add labels from all callers as the last columns in the training data
        Also ensure that if a true label is available for this dataset, it appears
        as the very last column
    """
    input:
        tsv = prepared_data,
        annot = rules.annotate.output
    params:
        truth = lambda wildcards: '^'+config['data'][wildcards.sample]['truth']+"~" if 'truth' in config['data'][wildcards.sample] and config['data'][wildcards.sample]['truth'] else ""
    output: config['out']+"/{sample}/prepared.tsv.gz"
    conda: "../envs/classify.yml"
    shell:
        "paste "
        "<(zcat {input.annot} | cut -f 3- | scripts/cgrep.bash - -v '{params.truth}') "
        "<(zcat {input.annot} | cut -f 3- | scripts/cgrep.bash - '{params.truth}') | "
        "sed 's/^\\t//' | paste <(zcat {input.tsv} | "
        "scripts/cgrep.bash - -v '~CLASS:' | "
        "scripts/cgrep.bash - -Evx '(CHROM|POS|REF)') - | gzip > {output}"


def train_output():
    """ return the output to the train rule, conditional on the tune config param """
    output = [config['out']+"/{sample}/model.rda", config['out']+"/{sample}/variable_importance.tsv"]
    if 'tune' in config and config['tune']:
        output.append(config['out']+"/{sample}/tune_matrix.tsv")
    return output


rule train:
    """ train the classifier """
    input: rules.add_truth.output
    params:
        balance = int(config['balance']) if 'balance' in config else 0
    output: train_output()
    conda: "../envs/classify.yml"
    shell:
        "Rscript scripts/train_RF.R {input} {params.balance} {output}"

rule plot_tune:
    """ plot the results of the hyperparameter tuning step """
    input: config['out']+"{sample}/tune_matrix.tsv"
    output: config['out']+"{sample}/tune.png"
    conda: "../envs/classify.yml"
    shell:
        "Rscript scripts/tune_plot.R {input} {output}"

rule predict:
    """ predict variants using the classifier """
    input:
        model = lambda wildcards: config['model'] \
            if 'model' in config and config['model'] else \
            expand(rules.train.output[0], sample=config['train']),
        predict = lambda wildcards: expand(rules.add_truth.output, sample=wildcards.sample)
    conda: "../envs/classify.yml"
    output: temp(config['out']+"/{sample}/predictions.tsv")
    shell:
        "Rscript scripts/predict_RF.R {input.predict} {input.model} {output}"

rule results:
    """
        join the predictions with the annotations
        also prefix the colnames of our method before merging
    """
    input:
        predict = rules.predict.output,
        annot = rules.annotate.output
    params:
        truth = lambda wildcards: config['data'][wildcards.sample]['truth'] if 'truth' in config['data'][wildcards.sample] and config['data'][wildcards.sample]['truth'] else ""
    output: config['out']+"/{sample}/results.tsv.gz"
    conda: "../envs/classify.yml"
    shell:
        "cat {input.predict} | paste <(zcat {input.annot}) "
        "<(read -r head && echo \"$head\" | tr '\\t' '\\n' | "
        "sed 's/response/CLASS:/' | sed 's/^/breakca~/' | "
        "paste -s && cat) | gzip > {output}"

rule prc_pts:
    """ generate single point precision recall metrics """
    input: rules.results.output
    params:
        truth = lambda wildcards: config['data'][wildcards.sample]['truth'] if 'truth' in config['data'][wildcards.sample] and config['data'][wildcards.sample]['truth'] else ""
    output: config['out']+"/{sample}/prc/pts/{caller}.txt"
    conda: "../envs/prc.yml"
    shell:
        "paste "
        "<(zcat {input} | scripts/cgrep.bash - '{params.truth}~CLASS:') "
        "<(zcat {input} | scripts/cgrep.bash - '{wildcards.caller}~CLASS:') | "
        "tail -n+2 | scripts/metrics.py -o {output}"


def sort_col(caller):
    if caller in config['prcols']:
        return config['prcols'][caller], False
    elif "*"+caller in config['prcols']:
        return config['prcols']["*"+caller], True
    else:
        return "", False


rule prc_curves:
    """ generate the points for a precision recall curve """
    input:
        annot = rules.annotate.output,
        predicts = lambda wildcards: rules.results.output if wildcards.caller == 'breakca' else prepared_data(wildcards)
    params:
        truth = lambda wildcards: config['data'][wildcards.sample]['truth'] if 'truth' in config['data'][wildcards.sample] and config['data'][wildcards.sample]['truth'] else "",
        predict_col = lambda wildcards: 'prob.1' if wildcards.caller == 'breakca' else sort_col(wildcards.caller)[0],
        flip = lambda wildcards: ["", "-f"][sort_col(wildcards.caller)[1]]
    output: config['out']+"/{sample}/prc/curves/{caller}.txt"
    conda: "../envs/prc.yml"
    shell:
        "paste "
        "<(zcat {input.annot} | scripts/cgrep.bash - '{params.truth}~CLASS:') "
        "<(zcat {input.predicts} | scripts/cgrep.bash - -F '{wildcards.caller}~{params.predict_col}') | "
        "tail -n+2 | scripts/statistics.py -o {output} {params.flip}"


def sort_cols(strict=False):
    return [
        caller[caller.startswith("*") and len("*"):]
        for caller in config['prcols'].keys()
        if not strict or config['prcols'][caller]
    ]


rule prc:
    """ create plot containing precision recall curves """
    input:
        pts = lambda wildcards: expand(
            rules.prc_pts.output, sample=wildcards.sample,
            caller=['breakca']+sort_cols()
        ),
        curves = lambda wildcards: expand(
            rules.prc_curves.output, sample=wildcards.sample,
            caller=['breakca']+sort_cols(True)
        )
    params:
        pts = lambda _, input: [k for j in zip(['--'+i+"_pt" for i in ['breakca']+sort_cols()], input.pts) for k in j],
        curves = lambda _, input: [k for j in zip(['--'+i for i in ['breakca']+sort_cols(True)], input.curves) for k in j]
    output: config['out']+"/{sample}/prc/results.png"
    conda: "../envs/prc.yml"
    shell:
        "scripts/prc.py {output} {params.pts} {params.curves}"
