# This is the Snakemake configuration file that specifies paths and 
# and options for the prepare pipeline. Anybody wishing to use
# the provided snakemake pipeline should first fill out this file with paths to
# their own data, as the Snakefile requires it.
# Note: this file is written in the YAML syntax (https://learnxinyminutes.com/docs/yaml/)


# The path to a text file specifying where to find read information for each sample
# Each row in the sample file should represent a different sample.
# The sample file should have 3 columns (each separated by a single tab):
#       <unique_sample_name> <fastq1_path> <fastq2_path>
# Alternatively, if you don't have FASTQ files, but you have BAM files, each
# row can have just two columns (where, again, each are separated by a tab):
#       <unique_sample_name> <bam_path>
# Note that if you provide a BAM file, it must have read group information.
# this is a required input!
sample_file: data/samples.tsv

# which samples should we execute the pipeline on?
# Comment out this line if you want to run all samples in the sample file
SAMP_NAMES: [SRR891269]

# The path to a reference genome for BWA
genome: /iblm/netapp/data1/external/GRC37/combined/bwa_index_assembly19/Homo_sapiens_assembly19.fasta

# Directory in which to output all of the output files
# Defined relative to whatever directory you execute the snakemake command in
out: out

# Which callers do you want to run to find SNVs?
# If you don't want to run the snp pipeline, set this to a falsey value or comment out the line
snp_callers: [gatk-snp, varscan-snp, vardict-snp, pg-snp]

# Which callers do you want to run to find indels?
# If you don't want to run the indel pipeline, set this to a falsey value or comment out the line
indel_callers: [gatk-indel, varscan-indel, vardict-indel, delly, pindel, illumina-manta, illumina-strelka, pg-indel, breakca]

# Parameters to use when calling bcftools to filter the VCF output of every caller script
# See http://www.htslib.org/doc/bcftools.html#view for all possible options
# Use an empty string or comment out this line if you'd like your VCFs unfiltered
# bcftools_params: "-M 2"

# what should our classifier predict?
# use "INS" if you want the classifier to predict insertions,
# use "DEL" if you want it to predict deletions,
# use "SNP" if you want it to predict SNVs, or
# use "." if you want it to simply predict whether any variant exists at that site
# __deprecated__: you can also specify a multilabel classification by providing a list instead of a single string (ex: ["INS", "DEL"] to predict both ins and dels)
label: "."

# Whether to "normalize" the VCF output of every caller script
# This option is recommended if you plan to feed the data to a random forest
# Normalization usually involves left-alignment and trimming of variants
# See https://genome.sph.umich.edu/wiki/Variant_Normalization for more info
# In our pipeline, the normalization step also reduces counts of variants that appear at the same position to 1
normalize: true

# Whether to replace NA values in the dataset before outputting the final TSV
# This option is recommended if you plan to feed the data to a random forest
# Unless otherwise specified in the Caller Specific Parameters below, NA values will be replaced with 0
fillna: true

# A list of filtering expressions for filtering the sites before outputting the final TSV
# A filtering expression consists of the following concatenated together:
#   - the caller id
#   - a tilde ~
#   - one of awk's comparison operators (the following are currently supported: >, <, ==)
#   - a value to filter on
# Comment out these lines to disable filtering
# Note that your filters may have unattended consequences if 'fillna' (above) is not set to true
snp_filter: ['gatk-snp~DP>10']
indel_filter: ['gatk-indel~DP>10']

# Whether to normalize weird numerical columns before outputting the final TSV
# ex: scientific notation or numbers followed by a percent sign
# This option is recommended if you plan to feed the data to a random forest
norm_numerics: true
